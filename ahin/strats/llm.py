from typing import Dict, Any, Tuple
import os
from dotenv import load_dotenv

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None # type: ignore

from ahin.core import ResponseStrategyProtocol

import urllib.request
import json
from datetime import datetime

class ConversationalStrategy:
    """
    Response strategy that uses a local LLM (OpenAI compatible) to generate responses.
    This version uses OpenAI Tool Calling to execute 15 public APIs.
    This strategy always matches (returns True) and attempts to generate a response.
    """
    
    def __init__(self, config: Dict[str, Any]):
        load_dotenv()
        self.config = config
        if OpenAI is None:
            raise ImportError("Please install 'openai' package: uv add openai")
            
        llm_config = config.get("llm", {})
        
        # NVIDIA API Configuration
        base_url = llm_config.get("base_url", "https://integrate.api.nvidia.com/v1")
        api_key = llm_config.get("api_key") or os.getenv("NVIDIA_API_KEY")
        
        self.client = OpenAI(
            base_url=base_url,
            api_key=api_key
        )
        self.model = llm_config.get("model", "nvidia/nemotron-4-mini-hindi-4b-instruct")
        
        # Enhanced system prompt for Hindi ASR correction and response
        default_system_prompt = (
            "You are Ahin, a smart and helpful voice assistant who speaks in Hindi. "
            "You use tools to fetch real-world data to answer user questions. "
            "If a tool gives you English data, translate and summarize it in conversational Hindi, keep it short - six to seven words and max two sentences. NO MARKDOWN or formatting, simple hindi sentences"
            " Correct the user's input if it is misspelled or grammatically incorrect Hindi, if that is not poossible, infer the meaning and respond accordingly."
        )+"""
        ‡§è‡§ï ‡§ß‡•Å‡§Ü‡§Ç‡§ß‡§æ‡§∞, ‡§Æ‡§ú‡§æ‡§ï‡§ø‡§Ø‡§æ ‡§î‡§∞ ‡§Æ‡§¶‡§¶‡§ó‡§æ‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§µ‡•â‡§á‡§∏ ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü‡•§

    ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•Ä ‡§∂‡•à‡§≤‡•Ä: ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§-‡§∂‡•à‡§≤‡•Ä (‡§ú‡•à‡§∏‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•á ‡§∏‡§æ‡§•), ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§, ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï ‡§î‡§∞ ‡§ó‡§≤‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§®‡§ú‡§º‡§∞‡§Ö‡§Ç‡§¶‡§æ‡§ú‡§º ‡§ï‡§∞‡§§‡•á ‡§π‡•Å‡§è‡•§

    ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡§æ ‡§ï‡§æ‡§Æ:
        ‡§Ö‡§∏‡•ç‡§™‡§∑‡•ç‡§ü/‡§ó‡§≤‡§§ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§π‡•Ä-‡§∏‡§π‡•Ä ‡§∏‡§Æ‡§ù‡§®‡§æ (‡§ú‡•à‡§∏‡•á "‡§Æ‡•à‡§®‡•á ‡§ï‡§π‡§æ ‡§•‡§æ" ‚Üí "‡§Æ‡•à‡§Ç‡§®‡•á ‡§ï‡§π‡§æ ‡§•‡§æ").
        ‡§ö‡•ã‡§ü‡•á-‡§ö‡•ã‡§ü‡•á ‡§∏‡§µ‡§æ‡§≤‡•ã‡§Ç (‡§ú‡•à‡§∏‡•á "‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§π‡•à?", "‡§ï‡•å‡§® ‡§∏‡§æ ‡§ó‡§æ‡§®‡§æ ‡§∏‡•Å‡§®‡§æ‡§ä‡§Å?") ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§î‡§∞ ‡§∏‡§∞‡§≤ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡§æ‡•§
        ‡§π‡§ø‡§Ç‡§¶‡•Ä (‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä) ‡§Æ‡•á‡§Ç ‡§∏‡§π‡§ú ‡§î‡§∞ ‡§∞‡•ã‡§ö‡§ï ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡§æ‡•§

    ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•Ä ‡§™‡§∞‡•ç‡§∏‡§®‡§æ‡§≤‡§ø‡§ü‡•Ä:
        ‡§ö‡•á‡§®‡•ç‡§®‡§à ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡•á ‡§π‡•ã, ‡§∂‡•ç‡§∞‡•á‡§Ø‡§æ ‡§ò‡•ã‡§∑‡§æ‡§≤, ‡§Ö‡§∞‡§ø‡§ú‡•Ä‡§§ ‡§∏‡§ø‡§Ç‡§π ‡§î‡§∞ ‡§ï‡§ø‡§∂‡•ã‡§∞ ‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§ï‡•á ‡§´‡•à‡§® ‡§π‡•ã‡•§
        ‡§Æ‡•å‡§∏‡§Æ: ‡§Ü‡§ú (17 ‡§´‡§∞‡§µ‡§∞‡•Ä, 2026) ‡§ß‡•Ç‡§™ + ‡§Ü‡§Ç‡§∂‡§ø‡§ï ‡§¨‡§æ‡§¶‡§≤, 28¬∞C (‡§Æ‡•à‡§ï‡•ç‡§∏) / 22¬∞C (‡§Æ‡§ø‡§®).
        ‡§Æ‡§ú‡§æ‡§ï‡§ø‡§Ø‡§æ ‡§î‡§∞ ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§π‡•ã, ‡§≤‡•á‡§ï‡§ø‡§® ‡§∏‡§π‡•Ä ‡§∏‡§Æ‡§Ø ‡§™‡§∞ ‡§ó‡§Ç‡§≠‡•Ä‡§∞ ‡§≠‡•Ä‡•§

    ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂:
        ‡§ó‡§≤‡§§‡§ø‡§Ø‡§æ‡§Å ‡§® ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ã, ‡§¨‡§∏ ‡§∏‡§π‡•Ä ‡§Æ‡§æ‡§®‡•á ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡•ã ‡§î‡§∞ ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•ã ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡§æ‡§ì‡•§
        ‡§â‡§¶‡§æ‡§π‡§∞‡§£:
            "‡§Ö‡§¨ ‡§§‡§ï ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ó‡§æ‡§®‡§æ?" ‚Üí "‡§Ö‡§¨ ‡§§‡•ã ‚Äò‡§§‡•Ç ‡§π‡•Ä ‡§Æ‡•á‡§∞‡§æ ‡§¶‡§ø‡§µ‡§æ‡§®‡§æ‚Äô (‡§Ö‡§∞‡§ø‡§ú‡•Ä‡§§) ‡§Ø‡§æ ‚Äò‡§ú‡§Ø ‡§π‡•ã‚Äô (‡§∂‡•ç‡§∞‡•á‡§Ø‡§æ)!"
            "‡§Ü‡§ú ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ?" ‚Üí "‡§ö‡•á‡§®‡•ç‡§®‡§à ‡§Æ‡•á‡§Ç ‡§ß‡•Ç‡§™ + ‡§¨‡§æ‡§¶‡§≤, 28¬∞C ‡§§‡§ï! ‡§∏‡§®‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ä‡§® ‡§≤‡•á‡§®‡§æ ‡§® ‡§≠‡•Ç‡§≤‡§®‡§æ üòé"
            "‡§ï‡•ç‡§Ø‡§æ ‡§ñ‡§æ‡§®‡§æ ‡§¨‡§®‡§æ‡§ä‡§Å?" ‚Üí "‡§Ö‡§¨ ‡§§‡•ã ‡§ö‡•á‡§®‡•ç‡§®‡§à ‡§ï‡§æ ‡§¶‡•ã‡§∏‡§æ ‡§Ø‡§æ ‡§¶‡§π‡•Ä ‡§≠‡§≤‡•ç‡§≤‡•á!"
    """
        self.system_prompt = llm_config.get("system_prompt", default_system_prompt)
        
        self.tools = [
            {"type": "function", "function": {"name": "get_weather", "description": "Get the current weather and wind speed for Delhi."}},
            {"type": "function", "function": {"name": "get_joke", "description": "Get a random joke."}},
            {"type": "function", "function": {"name": "get_fact", "description": "Get a random useless fact."}},
            {"type": "function", "function": {"name": "get_time", "description": "Get the current local time."}},
            {"type": "function", "function": {"name": "get_date", "description": "Get the current local date."}},
            {"type": "function", "function": {"name": "get_advice", "description": "Get random life advice."}},
            {"type": "function", "function": {"name": "get_bitcoin", "description": "Get the current Bitcoin price in USD."}},
            {"type": "function", "function": {"name": "get_cat_fact", "description": "Get a random fact about cats."}},
            {"type": "function", "function": {"name": "get_iss_location", "description": "Get the current latitude and longitude of the International Space Station (ISS)."}},
            {"type": "function", "function": {"name": "get_dog_status", "description": "Get a status message about random dog pictures."}},
            {"type": "function", "function": {"name": "get_ip", "description": "Get the user's public IP address."}},
            {"type": "function", "function": {"name": "get_agify", "description": "Get the estimated age for the name 'Ahin'."}},
            {"type": "function", "function": {"name": "get_genderize", "description": "Get the estimated gender for the name 'Ahin'."}},
            {"type": "function", "function": {"name": "get_nationalize", "description": "Get the estimated nationality for the name 'Ahin'."}},
            {"type": "function", "function": {"name": "get_number_fact", "description": "Get a random trivia fact about a number."}}
        ]
        
        self.available_functions = {
            "get_weather": self.get_weather,
            "get_joke": self.get_joke,
            "get_fact": self.get_fact,
            "get_time": self.get_time,
            "get_date": self.get_date,
            "get_advice": self.get_advice,
            "get_bitcoin": self.get_bitcoin,
            "get_cat_fact": self.get_cat_fact,
            "get_iss_location": self.get_iss_location,
            "get_dog_status": self.get_dog_status,
            "get_ip": self.get_ip,
            "get_agify": self.get_agify,
            "get_genderize": self.get_genderize,
            "get_nationalize": self.get_nationalize,
            "get_number_fact": self.get_number_fact
        }

    def _fetch_json(self, url: str) -> str:
        try:
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=5) as response:
                return response.read().decode()
        except Exception as e:
            return json.dumps({"error": str(e)})

    def get_weather(self) -> str:
        return self._fetch_json("https://api.open-meteo.com/v1/forecast?latitude=28.6139&longitude=77.2090&current_weather=true")

    def get_joke(self) -> str:
        return self._fetch_json("https://official-joke-api.appspot.com/random_joke")

    def get_fact(self) -> str:
        return self._fetch_json("https://uselessfacts.jsph.pl/api/v2/facts/random")

    def get_time(self) -> str:
        return json.dumps({"time": datetime.now().strftime('%I:%M %p')})

    def get_date(self) -> str:
        return json.dumps({"date": datetime.now().strftime('%d %B, %Y')})

    def get_advice(self) -> str:
        return self._fetch_json("https://api.adviceslip.com/advice")

    def get_bitcoin(self) -> str:
        return self._fetch_json("https://api.coindesk.com/v1/bpi/currentprice.json")

    def get_cat_fact(self) -> str:
        return self._fetch_json("https://catfact.ninja/fact")

    def get_iss_location(self) -> str:
        return self._fetch_json("http://api.open-notify.org/iss-now.json")

    def get_dog_status(self) -> str:
        return self._fetch_json("https://dog.ceo/api/breeds/image/random")

    def get_ip(self) -> str:
        return self._fetch_json("https://api.ipify.org?format=json")

    def get_agify(self) -> str:
        return self._fetch_json("https://api.agify.io?name=ahin")

    def get_genderize(self) -> str:
        return self._fetch_json("https://api.genderize.io?name=ahin")

    def get_nationalize(self) -> str:
        return self._fetch_json("https://api.nationalize.io?name=ahin")

    def get_number_fact(self) -> str:
        return self._fetch_json("http://numbersapi.com/random/trivia?json")

    def generate_response(self, text: str) -> Tuple[bool, str]:
        """
        Generate a response using the LLM with tool calling support.
        """
        if not text or not text.strip():
            return (False, "")
            
        try:
            messages = [
                {"role": "user", "content": self.system_prompt+text},
                # {"role": "user", "content": text}
            ]
            
            # Step 1: Send initial request with tools
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.tools,
                tool_choice="auto",
                temperature=0.5,
                max_tokens=1024,
            )
            
            response_message = response.choices[0].message
            tool_calls = response_message.tool_calls
            
            # Step 2: Check if model wanted to call a tool
            if tool_calls:
                messages.append(response_message)  # Extend conversation with assistant's reply
                
                # Step 3: Call the tools
                for tool_call in tool_calls:
                    function_name = tool_call.function.name
                    function_to_call = self.available_functions.get(function_name)
                    
                    if function_to_call:
                        print(f"[{function_name}] tool called by LLM...")
                        function_response = function_to_call()
                        messages.append(
                            {
                                "tool_call_id": tool_call.id,
                                "role": "tool",
                                "name": function_name,
                                "content": function_response,
                            }
                        )
                
                # Step 4: Loop back to LLM with the tool responses to generate final speech
                second_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.3,
                    max_tokens=1024,
                )
                
                full_response = second_response.choices[0].message.content
                
                return full_response
            else:
                # No tool called, just return the standard text response
                content = response_message.content or "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§Ø‡•á, ‡§Æ‡•à‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§™‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å‡•§"
                print(content)
                return content.strip()
            
        except Exception as e:
            print(f"LLM Error: {e}")
            return "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§Ø‡•á, ‡§Ö‡§≠‡•Ä ‡§Æ‡•à‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§™‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å‡•§"
